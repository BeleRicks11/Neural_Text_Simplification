{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU_CDlI-U-jK"
      },
      "source": [
        "# Text semplification project\n",
        "\n",
        "## Transformer model trained with supervised approach\n",
        "\n",
        "\n",
        "**Authors**: \n",
        "\n",
        "*   Davide Mercanti: davide.mercanti@studio.unibo.it\n",
        "*   Riccardo Fava: riccardo.fava6@studio.unibo.it\n",
        "*   Luca Bompani: luca.bompani4@studio.unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abW207tbVdyM"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zHx84Uxar9d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from utilities import resize\n",
        "resize(100)\n",
        "\n",
        "# Installing third part libraries\n",
        "!pip install fasttext > /dev/null\n",
        "!pip install \"tensorflow-text==2.8.*\" > /dev/null   \n",
        "!pip install datasets > /dev/null\n",
        "!pip install sacrebleu > /dev/null\n",
        "!pip install sacremoses > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U33oAoBGV3p9",
        "outputId": "5470e754-a78b-4c70-9ec7-6c3fe6306b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "try:\n",
        "    from keras.preprocessing.sequence import pad_sequences\n",
        "except ImportError:\n",
        "    from keras.utils import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle \n",
        "import typing\n",
        "import random\n",
        "from datasets import load_metric\n",
        "from typing import Any, Tuple\n",
        "import tensorflow_text as tf_text\n",
        "from os.path import join, dirname\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    COLAB = True\n",
        "except ModuleNotFoundError:\n",
        "    COLAB = False\n",
        "\n",
        "from data_cleaning import clean_data\n",
        "from data_preparation import build_vocabulary\n",
        "    \n",
        "from utilities import memoization, plot_trend\n",
        "\n",
        "@memoization(0)\n",
        "def word_tk_mem(arg):\n",
        "    return word_tokenize(arg)\n",
        "\n",
        "nltk.download('punkt')\n",
        "if COLAB:\n",
        "    drive.mount('/content/drive')\n",
        "    PATH = '/content/drive/MyDrive/UniBO/NLP'\n",
        "else:\n",
        "    PATH = './'\n",
        "use_builtins = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOE2DgK2VzBW"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "yPx9qY0EWBiZ",
        "outputId": "f2d63ca4-d50e-46a1-b684-60ddcfc40585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF 1 has shape (63006, 2)\n",
            "DF 2 has shape (1166, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence_1  \\\n",
              "0                       ma questo a cosa servirebbe ?   \n",
              "1   salve, avrei bisogno di una informazione piutt...   \n",
              "2       ciao a tutti avrei bisogno di un consiglio .    \n",
              "3   possibilmente uno che avesse bisogno dell aiuto .   \n",
              "4                   questa sarebbe una cosa positiva.   \n",
              "5   possibilmente uno che avesse bisogno dell aiuto .   \n",
              "6                         avrei bisogno di un aiuto .   \n",
              "7          quale sarebbe allora la soluzione giusta ?   \n",
              "8         salve , avrei bisogno di un vostro aiuto .    \n",
              "9         salve , avrei bisogno di un vostro aiuto .    \n",
              "10               quali consigli darebbe ai genitori ?   \n",
              "11        che ne sarebbe della natura della realtà ?    \n",
              "12                       avrei bisogno di un aiuto .    \n",
              "13               ora avrei bisogno di un consiglio .    \n",
              "14                 quale potrebbe essere la ragione ?   \n",
              "\n",
              "                                          sentence_2  \n",
              "0                       a che servono queste cose ?   \n",
              "1           ho bisogno di una informazione urgente .  \n",
              "2                   ho bisogno di un suo consiglio .  \n",
              "3                   ho bisogno di un vostro aiuto .   \n",
              "4                       questa era una nuova cosa .   \n",
              "5                          ho bisogno di un aiuto .   \n",
              "6                   ho bisogno di un vostro aiuto .   \n",
              "7                    è questa la soluzione giusta ?   \n",
              "8                 abbiamo bisogno del vostro aiuto .  \n",
              "9                      ho bisogno del vostro aiuto .  \n",
              "10           che consiglio vuole dare ai genitori ?   \n",
              "11             ma di che natura sono queste realtà ?  \n",
              "12  abbiamo bisogno di un aiuto soprattutto fisico .  \n",
              "13                  ho bisogno di un suo consiglio .  \n",
              "14          ma quale poteva essere questa ragione ?   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97cfe45d-576d-432b-9055-16fde073835c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ma questo a cosa servirebbe ?</td>\n",
              "      <td>a che servono queste cose ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>salve, avrei bisogno di una informazione piutt...</td>\n",
              "      <td>ho bisogno di una informazione urgente .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ciao a tutti avrei bisogno di un consiglio .</td>\n",
              "      <td>ho bisogno di un suo consiglio .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>possibilmente uno che avesse bisogno dell aiuto .</td>\n",
              "      <td>ho bisogno di un vostro aiuto .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>questa sarebbe una cosa positiva.</td>\n",
              "      <td>questa era una nuova cosa .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>possibilmente uno che avesse bisogno dell aiuto .</td>\n",
              "      <td>ho bisogno di un aiuto .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avrei bisogno di un aiuto .</td>\n",
              "      <td>ho bisogno di un vostro aiuto .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>quale sarebbe allora la soluzione giusta ?</td>\n",
              "      <td>è questa la soluzione giusta ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>salve , avrei bisogno di un vostro aiuto .</td>\n",
              "      <td>abbiamo bisogno del vostro aiuto .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>salve , avrei bisogno di un vostro aiuto .</td>\n",
              "      <td>ho bisogno del vostro aiuto .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>quali consigli darebbe ai genitori ?</td>\n",
              "      <td>che consiglio vuole dare ai genitori ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>che ne sarebbe della natura della realtà ?</td>\n",
              "      <td>ma di che natura sono queste realtà ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>avrei bisogno di un aiuto .</td>\n",
              "      <td>abbiamo bisogno di un aiuto soprattutto fisico .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ora avrei bisogno di un consiglio .</td>\n",
              "      <td>ho bisogno di un suo consiglio .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>quale potrebbe essere la ragione ?</td>\n",
              "      <td>ma quale poteva essere questa ragione ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97cfe45d-576d-432b-9055-16fde073835c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97cfe45d-576d-432b-9055-16fde073835c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97cfe45d-576d-432b-9055-16fde073835c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = clean_data(PATH)\n",
        "df.dropna(inplace=True)\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ncaopY58fKul"
      },
      "outputs": [],
      "source": [
        "TRAIN_DF, TEST_DF = train_test_split(df, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocabulary(train_df, test_df, tokenizer):\n",
        "    \"\"\"\n",
        "    Given train corpus and test corpus, builds the corresponding word vocabulary.\n",
        "\n",
        "    --------------\n",
        "    Return: \n",
        "      - word vocabulary: vocabulary index to word\n",
        "      - inverse word vocabulary: word to vocabulary index\n",
        "      - word listing: set of unique terms that build up the vocabulary\n",
        "    \"\"\"\n",
        "\n",
        "    corpus = list(pd.concat([\n",
        "        train_df['sentence_1'],\n",
        "        train_df['sentence_2'],\n",
        "        test_df['sentence_1'],\n",
        "        test_df['sentence_2']\n",
        "    ]))\n",
        "    word_to_idx = dict()  \n",
        "    idx_to_word = dict()\n",
        "    word_listing = set()\n",
        "\n",
        "    # Get all unique words in corpus \n",
        "    for sentence in corpus:\n",
        "        word_listing |= set(tokenizer(sentence))\n",
        "        \n",
        "   # Cast to list\n",
        "    word_listing = list(word_listing)\n",
        "\n",
        "    # Build vocabulary index to word <idx : word>\n",
        "    idx_to_word = dict(enumerate(word_listing, start=1))\n",
        "    idx_to_word[len(idx_to_word)+1] = \"[start]\"\n",
        "    idx_to_word[len(idx_to_word)+1] = \"[end]\"\n",
        "\n",
        "    # Build word_to_idx <word : idx>\n",
        "    word_to_idx = dict({_:k for k,_ in idx_to_word.items()})\n",
        "\n",
        "    return idx_to_word, word_to_idx, word_listing"
      ],
      "metadata": {
        "id": "dSqgPjB6qrhY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G1mQ3Mlfm9H",
        "outputId": "b496a3fa-c823-4106-aaab-d74ed86f5111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17978\n"
          ]
        }
      ],
      "source": [
        "IDX_TO_WORD, WORD_TO_IDX, WORD_LISTING = build_vocabulary(TRAIN_DF, TEST_DF, word_tk_mem)\n",
        "VOCAB_SIZE = len(IDX_TO_WORD)\n",
        "print(VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4pQwxpDd-Sb"
      },
      "source": [
        "## Load Pre-trained Word embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMrS3YQMkpqw",
        "outputId": "da671f62-f0db-49ac-e5f1-dc9375508388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fasttext model...\n",
            "200\n"
          ]
        }
      ],
      "source": [
        "# We load the pretrained FastText model\n",
        "\n",
        "EMBEDD_DIM = 200\n",
        "\n",
        "EMBEDD_FNAME = f'cc.it.{EMBEDD_DIM}.bin'  #ex. 'cc.it.100.bin'\n",
        "\n",
        "try: EMBEDDING_MODEL\n",
        "except NameError:\n",
        "    # Downloading FastText italian pre-trained model\n",
        "    fasttext.FastText.eprint = lambda x: None\n",
        "    try:\n",
        "        print('Loading fasttext model...', flush=True)\n",
        "        EMBEDDING_MODEL = fasttext.load_model(join(PATH, EMBEDD_FNAME))\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        fasttext.util.download_model('it', if_exists='ignore')  \n",
        "        EMBEDDING_MODEL = fasttext.load_model(join(PATH, EMBEDD_FNAME))\n",
        "\n",
        "print(EMBEDDING_MODEL.get_dimension())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g5X4TfZvj-Lt"
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(embedding_model, vocabulary_terms):\n",
        "  '''Returns a list of out-of-vocabulary (OOV) terms and the corresp. len'''\n",
        "  oov = set(vocabulary_terms).difference(set(embedding_model.words))\n",
        "  return list(oov), len(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnpy-9RylGU0",
        "outputId": "42adedae-4fda-49c7-ee32-a7185706513e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 1274 (7.087%)\n"
          ]
        }
      ],
      "source": [
        "_, n_oov_terms = check_OOV_terms(EMBEDDING_MODEL, WORD_LISTING)\n",
        "print(f\"Total OOV terms: {n_oov_terms} ({n_oov_terms*100/len(WORD_LISTING):.03f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_JQ4IU15qmJG"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = EMBEDDING_MODEL.get_dimension()\n",
        "\n",
        "def compute_embedding_matrix(embedding_model, idx_to_word):\n",
        "  \"\"\"\n",
        "  Return the embedding matrix of the train vocabulary:\n",
        "  \"\"\"\n",
        "  embedding_matrix = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIM), dtype='float32')\n",
        "\n",
        "  for idx in idx_to_word.keys():\n",
        "    embedding_matrix[idx] = embedding_model.get_word_vector(idx_to_word[idx])\n",
        "  return embedding_matrix\n",
        "\n",
        "EMBEDDING_MATRIX = compute_embedding_matrix(EMBEDDING_MODEL, IDX_TO_WORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjobQUAYq0t3",
        "outputId": "215eb5c1-cac4-4623-a21c-30e21127a99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights matrix size: (17979, 200)\n",
            "Vocab size: 17978\n"
          ]
        }
      ],
      "source": [
        "print(f'Weights matrix size: {EMBEDDING_MATRIX.shape}')\n",
        "print(f'Vocab size: {VOCAB_SIZE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XXrXrVUdrESS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "823a0705-fd05-4633-c48a-94ed71d7f581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44918, 2) (19251, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence_1  \\\n",
              "16105  [2759, 16687, 12002, 3265, 2743, 5993, 16327, ...   \n",
              "61303  [14662, 11910, 11147, 1792, 639, 1120, 6224, 1...   \n",
              "33781  [7242, 14662, 11910, 978, 17711, 7005, 6255, 7...   \n",
              "\n",
              "                                              sentence_2  \n",
              "16105  [17977, 2759, 16687, 12002, 3265, 5993, 16327,...  \n",
              "61303  [17977, 6814, 14662, 11910, 1792, 639, 1120, 6...  \n",
              "33781  [17977, 14662, 2557, 7005, 6255, 978, 7525, 17...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb32933f-6f0b-41b8-a8bf-6b476bd2cfa0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16105</th>\n",
              "      <td>[2759, 16687, 12002, 3265, 2743, 5993, 16327, ...</td>\n",
              "      <td>[17977, 2759, 16687, 12002, 3265, 5993, 16327,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61303</th>\n",
              "      <td>[14662, 11910, 11147, 1792, 639, 1120, 6224, 1...</td>\n",
              "      <td>[17977, 6814, 14662, 11910, 1792, 639, 1120, 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33781</th>\n",
              "      <td>[7242, 14662, 11910, 978, 17711, 7005, 6255, 7...</td>\n",
              "      <td>[17977, 14662, 2557, 7005, 6255, 978, 7525, 17...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb32933f-6f0b-41b8-a8bf-6b476bd2cfa0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb32933f-6f0b-41b8-a8bf-6b476bd2cfa0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb32933f-6f0b-41b8-a8bf-6b476bd2cfa0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "def word_to_idx_conversion(df, word_to_idx, len_sentence=None): \n",
        "  \"\"\"\n",
        "  Return input data (sentences) encoded\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  - corpus (train or test dataframe)\n",
        "\n",
        "  Return\n",
        "  ------\n",
        "  - DataFrame: sentences encoded using the word_to_idx dict\n",
        "  \"\"\"\n",
        "  # Conversion\n",
        "  converted_df = df.applymap(lambda _: [word_to_idx[token] for token in word_tk_mem(_)])\n",
        "  # Add \"[start] token at the first position of the sentence\"\n",
        "  converted_df['sentence_2'] = converted_df['sentence_2'].map(lambda _: [word_to_idx[\"[start]\"]] + _)\n",
        "  # Add \"[end] token at the last position of the sentence\"\n",
        "  converted_df['sentence_2'] = converted_df['sentence_2'].map(lambda _: _ + [word_to_idx[\"[end]\"]])\n",
        "\n",
        "  return converted_df\n",
        "\n",
        "ENCODED_TRAIN_DF = word_to_idx_conversion(TRAIN_DF, WORD_TO_IDX)\n",
        "m_len_input = max([len(i) for i in ENCODED_TRAIN_DF['sentence_1']])\n",
        "ENCODED_TEST_DF = word_to_idx_conversion(TEST_DF, WORD_TO_IDX, len_sentence=m_len_input)\n",
        "print(ENCODED_TRAIN_DF.shape, ENCODED_TEST_DF.shape)\n",
        "ENCODED_TRAIN_DF.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sentences(train_df, test_df):\n",
        "  \"\"\"\n",
        "  Returns zip objects containing pairs of complex and simplified sentences\n",
        "  padded according to the value MAX_SEQ_LENGTH (computed in order to handle\n",
        "  the majority of our data). Perform this operation for train, validation\n",
        "  and test set.\n",
        "  \"\"\"\n",
        "  cplx_train = [list(i) for i in train_df['sentence_1'].values] \n",
        "  smpl_train = [list(i) for i in train_df['sentence_2'].values]\n",
        "  cplx_test = [list(i) for i in test_df['sentence_1'].values] \n",
        "  smpl_test = [list(i) for i in test_df['sentence_2'].values]\n",
        "  # Computing padding size in order to handle the majority of our data (95-99%)\n",
        "  max_seq_length = int(np.quantile([len(seq) for seq in cplx_train + smpl_train + cplx_test + smpl_test], 0.99))\n",
        "  # Ceation of the validation set\n",
        "  cplx_test, cplx_valid, smpl_test, smpl_valid = train_test_split(cplx_test, smpl_test, test_size=0.3, random_state=42)\n",
        "  # Apply padding\n",
        "  cplx_train = pad_sequences(cplx_train, padding=\"post\", maxlen=max_seq_length)\n",
        "  smpl_train = pad_sequences(smpl_train, padding=\"post\", maxlen=max_seq_length + 1)\n",
        "  cplx_test = pad_sequences(cplx_test, padding=\"post\", maxlen=max_seq_length)\n",
        "  smpl_test = pad_sequences(smpl_test, padding=\"post\", maxlen=max_seq_length + 1)\n",
        "  cplx_valid = pad_sequences(cplx_valid, padding=\"post\", maxlen=max_seq_length)\n",
        "  smpl_valid = pad_sequences(smpl_valid, padding=\"post\", maxlen=max_seq_length + 1)\n",
        "  return tuple(zip(cplx_train, smpl_train)), tuple(zip(cplx_test, smpl_test)), tuple(zip(cplx_valid, smpl_valid)), max_seq_length\n",
        "\n",
        "TRAIN_PAIRS, TEST_PAIRS, VALID_PAIRS, MAX_SEQ_LENGHT = pad_sentences(ENCODED_TRAIN_DF, ENCODED_TEST_DF)\n",
        "print(f\"Max_sequence_lenght: {MAX_SEQ_LENGHT}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h88AvriIGWtl",
        "outputId": "6f913e7e-a526-4487-f320-2484d7f87340"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max_sequence_lenght: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "def format_dataset(cplx, simpl):\n",
        "  return ({\"encoder_inputs\": cplx, \"decoder_inputs\": simpl[:, :-1],}, simpl[:, 1:])\n",
        "\n",
        "def make_dataset(pairs, batch_size): \n",
        "  \"\"\"\n",
        "  Build dataset objects for train, validation and test set\n",
        "  \n",
        "  \"\"\"\n",
        "  complex_sent, simpl_sent = zip(*pairs)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((list(complex_sent), list(simpl_sent)))\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.map(format_dataset)\n",
        "  return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "TRAIN_DATASET = make_dataset(TRAIN_PAIRS, BATCH_SIZE)\n",
        "TEST_DATASET = make_dataset(TEST_PAIRS, BATCH_SIZE)\n",
        "VALID_DATASET = make_dataset(VALID_PAIRS, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "05Uwm6EasWSL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in TRAIN_DATASET.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P7wDOGQOjcp",
        "outputId": "fed73178-310a-4b7b-9526-c4c2bb6954e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 35)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 35)\n",
            "targets.shape: (64, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHUmqgmQmrjP"
      },
      "source": [
        "## Defining model and utility functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, initializer, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        if initializer != \"uniform\":\n",
        "          self.token_embeddings = layers.Embedding(\n",
        "              input_dim=vocab_size, output_dim=embed_dim, embeddings_initializer=initializer, mask_zero=True)\n",
        "        else:\n",
        "            self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim, embeddings_initializer=initializer)\n",
        "\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ],
      "metadata": {
        "id": "1lgo-jkJKejc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(initializer = \"uniform\", latent_dim = 2048, num_heads = 8):\n",
        "  \"\"\"\n",
        "  Return the model built using the inserted hyper-parameters\n",
        "  \n",
        "  \"\"\"\n",
        "  global MAX_SEQ_LENGHT, VOCAB_SIZE, EMBEDDING_DIM\n",
        "  encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "  x = PositionalEmbedding(MAX_SEQ_LENGHT, VOCAB_SIZE+1, EMBEDDING_DIM, initializer)(encoder_inputs)\n",
        "  encoder_outputs = TransformerEncoder(EMBEDDING_DIM, latent_dim, num_heads)(x)\n",
        "  encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "  decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "  encoded_seq_inputs = keras.Input(shape=(None, EMBEDDING_DIM), name=\"decoder_state_inputs\")\n",
        "  x = PositionalEmbedding(MAX_SEQ_LENGHT, VOCAB_SIZE+1, EMBEDDING_DIM, initializer)(decoder_inputs)\n",
        "  x = TransformerDecoder(EMBEDDING_DIM, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  decoder_outputs = layers.Dense(VOCAB_SIZE+1, activation=\"softmax\")(x)\n",
        "  decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "  decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "  return keras.Model(\n",
        "      [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n"
      ],
      "metadata": {
        "id": "SUWrHOKrNffj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_vocab_data(vocab_data_path):\n",
        "  \"\"\"\n",
        "  Save Embedding Matrix, vocabulary and vocab_dictionaries\n",
        "  \n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Save the data\n",
        "    filename = join(vocab_data_path, 'word_to_idx.p')\n",
        "    with open(filename, 'wb') as outfile:\n",
        "        pickle.dump(WORD_TO_IDX, outfile)\n",
        "    filename = join(vocab_data_path, 'idx_to_word.p')\n",
        "    with open(filename, 'wb') as outfile:\n",
        "        pickle.dump(IDX_TO_WORD, outfile)\n",
        "    filename = join(vocab_data_path, 'word_listing.p')\n",
        "    with open(filename, 'wb') as outfile:\n",
        "        pickle.dump(WORD_LISTING, outfile)\n",
        "    filename = join(vocab_data_path, 'embedding_matrix.p')\n",
        "    with open(filename, 'wb') as outfile:\n",
        "      pickle.dump(EMBEDDING_MATRIX, outfile)\n",
        "    print(\"Data saved!\")\n",
        "  except Exception:\n",
        "    print('**NOT** saved!')"
      ],
      "metadata": {
        "id": "utfsx4GiWu6v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(model, input_sentence, idx_to_word, word_to_idx):\n",
        "  \"\"\"\n",
        "  Performs the decoding of the sequence predicted from the model\n",
        "\n",
        "  \"\"\"\n",
        "  tokenized_input_sentence = np.array(input_sentence).reshape((1,-1))\n",
        "  tokenized_input_sentence = tf.convert_to_tensor(tokenized_input_sentence)\n",
        "  decoded_sentence = \"[start]\"\n",
        "\n",
        "  for i in range(MAX_SEQ_LENGHT):\n",
        "      tokenized_target_sentence = np.array([word_to_idx[token] for token in decoded_sentence.split(\" \")]).reshape((1,-1))\n",
        "      tokenized_target_sentence = pad_sequences(tokenized_target_sentence, padding=\"post\", maxlen=MAX_SEQ_LENGHT)\n",
        "      tokenized_target_sentence = tf.convert_to_tensor(tokenized_target_sentence)\n",
        "      predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
        "      sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "      sampled_token = idx_to_word[sampled_token_index]\n",
        "      decoded_sentence += \" \" + sampled_token\n",
        "      if sampled_token == \"[end]\":\n",
        "          break\n",
        "  return decoded_sentence\n",
        "\n",
        "def convert_seq_to_text(input_sentence, idx_to_word):\n",
        "  \"\"\"\n",
        "  Convert a sequence of token indexes into text\n",
        "\n",
        "  \"\"\"\n",
        "  result = \"\"\n",
        "  for token in input_sentence:\n",
        "    if token != 0:\n",
        "      result += idx_to_word[token] + \" \"\n",
        "  return result"
      ],
      "metadata": {
        "id": "CzzQFOmzZ4R_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_pairs, tokenizer):\n",
        "  \"\"\"\n",
        "  Performs the evaluation of the model computing the BLEU and SARI metrics\n",
        "\n",
        "  \"\"\"\n",
        "  global IDX_TO_WORD, WORD_TO_IDX\n",
        "  test_texts = [pair[0] for pair in test_pairs]\n",
        "  bleu_metric = load_metric(\"bleu\")\n",
        "  sari_metric = load_metric(\"sari\")\n",
        "  bleu_pred, bleu_ref = [], []\n",
        "  sari_pred, sari_ref, sari_sources = [], [], []\n",
        "\n",
        "  for input_sentence in test_texts:\n",
        "  #for input_sentence in test_texts[:1000]:\n",
        "    translated_sentence = decode_sequence(model, input_sentence, IDX_TO_WORD, WORD_TO_IDX)\n",
        "    # Removing [start] and [end] tags\n",
        "    translated_sentence = translated_sentence.replace(\"[start] \", '')\n",
        "    translated_sentence = translated_sentence.replace(\" [end]\", '')\n",
        "    # BLEU\n",
        "    bleu_pred.append([token for token in tokenizer(translated_sentence)])\n",
        "    bleu_ref.append([[token for token in tokenizer(convert_seq_to_text(input_sentence, IDX_TO_WORD))]])\n",
        "    # SARI\n",
        "    sari_pred.append(translated_sentence)\n",
        "    sari_sources.append(convert_seq_to_text(input_sentence, IDX_TO_WORD))\n",
        "    sari_ref.append([convert_seq_to_text(input_sentence, IDX_TO_WORD)])\n",
        "\n",
        "  # Computing metrics\n",
        "  bleu_score = bleu_metric.compute(predictions=bleu_pred, references = bleu_ref)\n",
        "  sari_score = sari_metric.compute(sources=sari_sources, predictions=sari_pred, references=sari_ref)\n",
        "  return bleu_score, sari_score"
      ],
      "metadata": {
        "id": "eU4W63C9qYnW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters tuning"
      ],
      "metadata": {
        "id": "1RuPOJMF7RtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_hyperparms(params_dict, epochs):\n",
        "  \"\"\"\n",
        "  Performs the hyper-parameter tuning searching for the best configuration\n",
        "\n",
        "  \"\"\"\n",
        "  global TRAIN_DATASET, VALID_DATASET, VALID_PAIRS, word_tk_mem\n",
        "  results = pd.DataFrame(columns=list(params_dict.keys()) + [\"SARI\"] + [\"BLEU\"])\n",
        "  try:\n",
        "    for latent_dim in params_dict['latent_dim']:\n",
        "      for heads in params_dict['n_heads']:\n",
        "        for LR in params_dict['learning_rate']:\n",
        "          initializer = keras.initializers.Constant(EMBEDDING_MATRIX)\n",
        "          transformer = get_model(initializer, latent_dim, heads)\n",
        "          callbacks = [\n",
        "              EarlyStopping(patience=3, verbose=1),\n",
        "              ReduceLROnPlateau(factor=0.1, patience=3, verbose=0)]\n",
        "          transformer.compile(Adam(learning_rate = LR), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "          print(f\"LR = {LR} | Latent_dimension = {latent_dim} | Number of heads = {heads}\")\n",
        "          history = transformer.fit(TRAIN_DATASET, \n",
        "                                    epochs=epochs, \n",
        "                                    validation_data=VALID_DATASET,\n",
        "                                    callbacks=callbacks,\n",
        "                                    verbose=0)\n",
        "          bleu_score, sari_score = evaluate_model(transformer, VALID_PAIRS, word_tk_mem)\n",
        "          print(f\"BLEU score: {round(bleu_score['bleu'], 3)}, SARI score: {round(sari_score['sari'], 3)}\\n\")\n",
        "          results = results.append({\"learning_rate\": LR, \"latent_dim\": latent_dim, \"SARI\": round(sari_score['sari'], 3),\\\n",
        "                                                \"BLEU\": round(bleu_score['bleu'], 3)}, ignore_index=True)\n",
        "  except KeyboardInterrupt:\n",
        "    print('\\n === Manually aborted, returning results so far. ===')\n",
        "  finally:\n",
        "    return results"
      ],
      "metadata": {
        "id": "7gOjqoPOsixb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_dict = {\n",
        "      \"learning_rate\": [1e-3, 1e-4, 1e-5],\n",
        "      \"latent_dim\": [2048, 4096],\n",
        "      \"n_heads\": [8, 16]\n",
        "      }\n",
        "\n",
        "tune_hyperparms(params_dict, epochs=30)"
      ],
      "metadata": {
        "id": "sFvqbCCa59pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best configuration of the Hyperparameters found:\n",
        "\n",
        "---\n",
        "\n",
        "LR = 0.0001 | Latent_dimension = 2048 | Number of heads = 8\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "_XKd4t0wc_jY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Best Model"
      ],
      "metadata": {
        "id": "r3TGtGVy6-wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definition of the best configuration of the hyper-parameters\n",
        "\n",
        "LATENT_DIM = 2048\n",
        "N_HEADS = 8\n",
        "INITIALIZER = keras.initializers.Constant(EMBEDDING_MATRIX)\n",
        "\n",
        "transformer = get_model(INITIALIZER, LATENT_DIM, N_HEADS)\n",
        "\n",
        "transformer.summary()"
      ],
      "metadata": {
        "id": "Y1-_xGMVN5af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67283915-f486-41f0-b7d1-353fc08f61b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 200)   3602800     ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 200)   2107248     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 17979)  10609227    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,319,275\n",
            "Trainable params: 16,319,275\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With this cell we can load from the Drive the weights of vocab data and trained model \n",
        "\n",
        "LOAD_DATA = False\n",
        "checkpoint_path = join(PATH, \"training_200/cp.ckpt\")\n",
        "vocab_data_path = join(PATH, \"vocab_data/vocab_data_200\")\n",
        "\n",
        "if LOAD_DATA:\n",
        "  try:\n",
        "    # Load vocab data\n",
        "    filename = join(vocab_data_path, 'embedding_matrix.p')\n",
        "    with open(filename, 'rb') as outfile:\n",
        "        EMBEDDING_MATRIX = pickle.load(outfile)\n",
        "\n",
        "    filename = join(vocab_data_path, 'word_to_idx.p')\n",
        "    with open(filename, 'rb') as outfile:\n",
        "        WORD_TO_IDX = pickle.load(outfile)\n",
        "\n",
        "    filename = join(vocab_data_path, 'idx_to_word.p')    \n",
        "    with open(filename, 'rb') as outfile:\n",
        "        IDX_TO_WORD = pickle.load(outfile)\n",
        "\n",
        "    filename = join(vocab_data_path, 'word_listing.p')\n",
        "    with open(filename, 'rb') as outfile:\n",
        "      WORD_LISTING = pickle.load(outfile)\n",
        "\n",
        "    # Loads the weights\n",
        "    transformer.load_weights(checkpoint_path)\n",
        "    print(\"Data loaded!\")\n",
        "  except Exception:\n",
        "    print('**NOT** loaded!')"
      ],
      "metadata": {
        "id": "of5zgYYAOq_6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We train the model with the best configuration of the hyper-parameters\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "if LOAD_DATA == False:\n",
        "  #Define the callbacks\n",
        "  callbacks = [\n",
        "      EarlyStopping(patience=4, verbose=1),\n",
        "      ReduceLROnPlateau(factor=0.1, patience=4, verbose=1),\n",
        "      ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "  ]\n",
        "\n",
        "  transformer.compile(Adam(learning_rate = 1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  history = transformer.fit(TRAIN_DATASET, \n",
        "                            epochs=EPOCHS, \n",
        "                            validation_data=TEST_DATASET,\n",
        "                            callbacks=callbacks\n",
        "                            )\n",
        "  # Save vocab data\n",
        "  save_vocab_data(vocab_data_path)"
      ],
      "metadata": {
        "id": "hiIYoey6N5dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544d563a-0f14-449c-9d97-65c5bb040310"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 1.4685 - accuracy: 0.3872\n",
            "Epoch 1: val_loss improved from inf to 0.97637, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 86s 108ms/step - loss: 1.4685 - accuracy: 0.3872 - val_loss: 0.9764 - val_accuracy: 0.5133 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.8515 - accuracy: 0.5622\n",
            "Epoch 2: val_loss improved from 0.97637 to 0.73351, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 78s 111ms/step - loss: 0.8515 - accuracy: 0.5622 - val_loss: 0.7335 - val_accuracy: 0.6116 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.6305\n",
            "Epoch 3: val_loss improved from 0.73351 to 0.62124, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 78s 112ms/step - loss: 0.6776 - accuracy: 0.6305 - val_loss: 0.6212 - val_accuracy: 0.6528 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.6691\n",
            "Epoch 4: val_loss improved from 0.62124 to 0.55510, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 112ms/step - loss: 0.5801 - accuracy: 0.6691 - val_loss: 0.5551 - val_accuracy: 0.6814 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.6971\n",
            "Epoch 5: val_loss improved from 0.55510 to 0.51199, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 113ms/step - loss: 0.5131 - accuracy: 0.6971 - val_loss: 0.5120 - val_accuracy: 0.6996 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.7187\n",
            "Epoch 6: val_loss improved from 0.51199 to 0.47993, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 113ms/step - loss: 0.4621 - accuracy: 0.7187 - val_loss: 0.4799 - val_accuracy: 0.7142 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.7358\n",
            "Epoch 7: val_loss improved from 0.47993 to 0.45430, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 114ms/step - loss: 0.4209 - accuracy: 0.7358 - val_loss: 0.4543 - val_accuracy: 0.7285 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.7501\n",
            "Epoch 8: val_loss improved from 0.45430 to 0.43393, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 113ms/step - loss: 0.3872 - accuracy: 0.7501 - val_loss: 0.4339 - val_accuracy: 0.7373 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.7634\n",
            "Epoch 9: val_loss improved from 0.43393 to 0.41964, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 113ms/step - loss: 0.3577 - accuracy: 0.7634 - val_loss: 0.4196 - val_accuracy: 0.7476 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.7756\n",
            "Epoch 10: val_loss improved from 0.41964 to 0.40564, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 113ms/step - loss: 0.3315 - accuracy: 0.7756 - val_loss: 0.4056 - val_accuracy: 0.7529 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.7862\n",
            "Epoch 11: val_loss improved from 0.40564 to 0.39526, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 114ms/step - loss: 0.3093 - accuracy: 0.7862 - val_loss: 0.3953 - val_accuracy: 0.7592 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.7962\n",
            "Epoch 12: val_loss improved from 0.39526 to 0.38765, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 113ms/step - loss: 0.2891 - accuracy: 0.7962 - val_loss: 0.3876 - val_accuracy: 0.7628 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.8048\n",
            "Epoch 13: val_loss improved from 0.38765 to 0.38009, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 113ms/step - loss: 0.2712 - accuracy: 0.8048 - val_loss: 0.3801 - val_accuracy: 0.7665 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.8127\n",
            "Epoch 14: val_loss improved from 0.38009 to 0.37561, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 113ms/step - loss: 0.2550 - accuracy: 0.8127 - val_loss: 0.3756 - val_accuracy: 0.7694 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.8199\n",
            "Epoch 15: val_loss improved from 0.37561 to 0.37127, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 114ms/step - loss: 0.2410 - accuracy: 0.8199 - val_loss: 0.3713 - val_accuracy: 0.7723 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.8268\n",
            "Epoch 16: val_loss improved from 0.37127 to 0.36671, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 80s 114ms/step - loss: 0.2272 - accuracy: 0.8268 - val_loss: 0.3667 - val_accuracy: 0.7744 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.8336\n",
            "Epoch 17: val_loss improved from 0.36671 to 0.36548, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 113ms/step - loss: 0.2151 - accuracy: 0.8336 - val_loss: 0.3655 - val_accuracy: 0.7749 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.8394\n",
            "Epoch 18: val_loss improved from 0.36548 to 0.36320, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 113ms/step - loss: 0.2039 - accuracy: 0.8394 - val_loss: 0.3632 - val_accuracy: 0.7772 - lr: 1.0000e-04\n",
            "Epoch 19/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.8448\n",
            "Epoch 19: val_loss improved from 0.36320 to 0.36187, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 113ms/step - loss: 0.1942 - accuracy: 0.8448 - val_loss: 0.3619 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
            "Epoch 20/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.8504\n",
            "Epoch 20: val_loss did not improve from 0.36187\n",
            "702/702 [==============================] - 78s 112ms/step - loss: 0.1845 - accuracy: 0.8504 - val_loss: 0.3628 - val_accuracy: 0.7792 - lr: 1.0000e-04\n",
            "Epoch 21/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.8554\n",
            "Epoch 21: val_loss improved from 0.36187 to 0.36024, saving model to /content/drive/MyDrive/UniBO/NLP/training_200/cp.ckpt\n",
            "702/702 [==============================] - 79s 113ms/step - loss: 0.1759 - accuracy: 0.8554 - val_loss: 0.3602 - val_accuracy: 0.7810 - lr: 1.0000e-04\n",
            "Epoch 22/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.8592\n",
            "Epoch 22: val_loss did not improve from 0.36024\n",
            "702/702 [==============================] - 79s 112ms/step - loss: 0.1689 - accuracy: 0.8592 - val_loss: 0.3610 - val_accuracy: 0.7811 - lr: 1.0000e-04\n",
            "Epoch 23/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.8638\n",
            "Epoch 23: val_loss did not improve from 0.36024\n",
            "702/702 [==============================] - 78s 112ms/step - loss: 0.1612 - accuracy: 0.8638 - val_loss: 0.3620 - val_accuracy: 0.7818 - lr: 1.0000e-04\n",
            "Epoch 24/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.8674\n",
            "Epoch 24: val_loss did not improve from 0.36024\n",
            "702/702 [==============================] - 78s 111ms/step - loss: 0.1548 - accuracy: 0.8674 - val_loss: 0.3637 - val_accuracy: 0.7810 - lr: 1.0000e-04\n",
            "Epoch 25/30\n",
            "702/702 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.8710\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.36024\n",
            "702/702 [==============================] - 78s 112ms/step - loss: 0.1491 - accuracy: 0.8710 - val_loss: 0.3639 - val_accuracy: 0.7829 - lr: 1.0000e-04\n",
            "Epoch 25: early stopping\n",
            "Data saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history): \n",
        "  \"\"\"\n",
        "  Plot the graph with training and test loss\n",
        "  \n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(len(loss))\n",
        "  _ = plt.figure()\n",
        "\n",
        "  plt.title(\"Training and test Loss\")\n",
        "  plt.plot(epochs, loss, color='blue', label='Train')\n",
        "  plt.plot(epochs, val_loss, color='orange', label='Val')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "    \n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "MttK8MB7PkQ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "71aac975-1ec9-43fc-99f1-4c9d58241caf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5d338c8vCwmEHSJbWBNRwCpYxOIKtdalClqrEqutt1rUu9a21qXY9tbH1j629fax3vW2xdZqF6Faq8WqdWm1WDdA3AAFkUUCAhFk38nv+eM6ITNhJiSQyUky3/frdV5z5pwzM7/D6Hxzrus655i7IyIiUi0n7gJERKR5UTCIiEgSBYOIiCRRMIiISBIFg4iIJFEwiIhIEgWDNDtm9pSZfbWxt42TmS0xs8/FXYdIfeTFXYC0Dma2KeFpO2A7sDt6frm7/7G+7+Xup2Vi2+bKzO4HKtz9+wf4PgOAxUC+u+9Ks83NQJm7X3ggnyWtm4JBGoW7t6+eN7MlwGXu/lzt7cwsL92Plog0D2pKkowyszFmVmFmN5jZSuC3ZtbFzP5mZpVm9kk0X5LwmhfM7LJo/mIz+7eZ3R5tu9jMTtvPbQea2XQz22hmz5nZ3Wb2hzR116fGH5rZS9H7PWNm3RPWX2RmS81sjZl9r45/n4nAl4HrzWyTmT0eLe9tZo9En7/YzK5OeM0oM5tlZhvMbJWZ3RGtmh49rovea3Q9vqLEWsaZ2VwzWxft35CEdTeY2fJoX+eb2Un7qEVaMAWDNIWeQFegPzCR8N/db6Pn/YCtwC/qeP3RwHygO/BT4DdmZvux7YPADKAbcDNwUR2fWZ8aLwD+AzgIaANcC2BmQ4F7ovfvHX1eCSm4+2Tgj8BP3b29u59pZjnA48BbQB/gJOBbZnZK9LKfAz93945AKfBQtPyE6LFz9F6v1LF/ScxsMDAF+BZQDDwJPG5mbczsEOAq4Ch37wCcAizZRy3SgikYpClUATe5+3Z33+rua9z9EXff4u4bgVuBE+t4/VJ3v9fddwMPAL2AHg3Z1sz6AUcB/+XuO9z938C0dB9Yzxp/6+4L3H0r4QdxeLT8S8Df3H26u28HfhD9G9TXUUCxu98S1boIuBeYEK3fCZSZWXd33+TurzbgvdM5H3jC3Z91953A7UBb4BhCX1EBMNTM8t19ibt/kMFaJGYKBmkKle6+rfqJmbUzs19FTS0bCE0gnc0sN83rV1bPuPuWaLZ9A7ftDaxNWAawLF3B9axxZcL8loSaeie+t7tvBtak+6wU+gO9oyaddWa2DriRmjC8FBgMvGdmM83sjAa8dzq9gaUJNVcR9qGPuy8kHEncDKw2s6lm1juDtUjMFAzSFGpfwvc7wCHA0VETRHUTSLrmocbwEdDVzNolLOtbx/YHUuNHie8dfWa3Orav/e+zDFjs7p0Tpg7ufjqAu7/v7uWEJqyfAH82s6IU79MQKwiBVF2zRfuwPPrMB939uGgbjz63rlqkBVMwSBw6ENrs15lZV+CmTH+guy8FZgE3R+3mo4EzM1Tjn4EzzOw4M2sD3ELd/6+tAgYlPJ8BbIw6fNuaWa6ZHWZmRwGY2YVmVhz9Vb8uek0VUBk9Jr5XKjlmVpgwFRCawr5gZieZWT4hGLcDL5vZIWb22Wi7bYR/l6p91CItmIJB4nAnof36Y+BV4O9N9LlfBkYTmnV+BPyJ8OOXyn7X6O5zga8TOrs/Aj4BKup4yW8I7ffrzOyxqH/kDEKfxeKohl8DnaLtTwXmWjh35OfAhKjvZguhL+Sl6L0+k+bzygk/7tXTB+4+H7gQ+J/o884EznT3HYT+hdui5SsJRweT6qqlnv9U0kyZbtQj2crM/gS85+4ZP2IRaUl0xCBZw8yOMrNSM8sxs1OB8cBjcdcl0tzozGfJJj2BvxA6giuAK939jXhLEml+1JQkIiJJ1JQkIiJJWlxTUvfu3X3AgAFxlyEi0qK8/vrrH7t7cX22bXHBMGDAAGbNmhV3GSIiLYqZLd33VoGakkREJImCQUREkigYREQkSYvrYxARaaidO3dSUVHBtm3b9r1xC1dYWEhJSQn5+fn7/R4KBhFp9SoqKujQoQMDBgwg/T2eWj53Z82aNVRUVDBw4MD9fh81JYlIq7dt2za6devWqkMBwMzo1q3bAR8ZKRhEJCu09lCo1hj7mTXB8M47MGkSrFu3721FRLJZ1gTD4sVw222wYEHclYhItlmzZg3Dhw9n+PDh9OzZkz59+ux5vmPHjjpfO2vWLK6++uomqjTIms7n0tLw+MEHMGpUvLWISHbp1q0bb775JgA333wz7du359prr92zfteuXeTlpf45HjlyJCNHjmySOqtlzRHDoOhmhx98EG8dIiIAF198MVdccQVHH300119/PTNmzGD06NGMGDGCY445hvnz5wPwwgsvcMYZZwAhVC655BLGjBnDoEGDuOuuuzJSW9YcMbRtC717KxhEst23vgXRH++NZvhwuPPOhr+uoqKCl19+mdzcXDZs2MCLL75IXl4ezz33HDfeeCOPPPLIXq957733eP7559m4cSOHHHIIV1555QGds5BK1gQDhOYkBYOINBfnnnsuubm5AKxfv56vfvWrvP/++5gZO3fuTPmaL3zhCxQUFFBQUMBBBx3EqlWrKCkpadS6si4Ynnkm7ipEJE7785d9phQVFe2Z/8EPfsDYsWN59NFHWbJkCWPGjEn5moKCgj3zubm57Nq1q9Hrypo+BgjBsGIFbN0adyUiIsnWr19Pnz59ALj//vtjrSVjwWBm95nZajObs4/tjjKzXWb2pUzVUq16ZNKiRZn+JBGRhrn++uuZNGkSI0aMyMhRQENk7J7PZnYCsAn4nbsflmabXOBZYBtwn7v/eV/vO3LkSN/fG/XMmAFHHw2PPQbjx+/XW4hIC/Tuu+8yZMiQuMtoMqn218xed/d6jXvN2BGDu08H1u5js28AjwCrM1VHorKy8KgOaBGR9GLrYzCzPsDZwD1N9Zldu0LnzgoGEZG6xNn5fCdwg7tX7WtDM5toZrPMbFZlZeUBfaiGrIqI1C3O4aojganRlQC7A6eb2S53f6z2hu4+GZgMoY/hQD60tBRmzz6QdxARad1iO2Jw94HuPsDdBwB/Bv4zVSg0ttJSWLIEYu70FxFptjJ2xGBmU4AxQHczqwBuAvIB3P2XmfrcfSktDaGwbBkcwA2ORERarUyOSip3917unu/uJe7+G3f/ZapQcPeL6zNUtTEkXmVVRKQpjB07lqeffjpp2Z133smVV16ZcvsxY8awv8PyG0NWnfkMNcGwcGG8dYhI9igvL2fq1KlJy6ZOnUp5eXlMFdUt64KhTx8oKNARg4g0nS996Us88cQTe27Ks2TJElasWMGUKVMYOXIkw4YN46abboq5yhpZdRE9gJyccG8GBYNIlnr9W/BJI193u8tw+HT6q/N17dqVUaNG8dRTTzF+/HimTp3Keeedx4033kjXrl3ZvXs3J510Em+//TaHH35449a2H7LuiAF0LoOINL3E5qTqZqSHHnqII488khEjRjB37lzmzZsXc5VB1h0xQAiG558HdwinUYhI1qjjL/tMGj9+PN/+9reZPXs2W7ZsoWvXrtx+++3MnDmTLl26cPHFF7Nt27ZYaqsta48YNm+G1U1yhSYREWjfvj1jx47lkksuoby8nA0bNlBUVESnTp1YtWoVTz31VNwl7pG1RwwQmpN69Ii3FhHJHuXl5Zx99tlMnTqVQw89lBEjRnDooYfSt29fjj322LjL2yPrg+GYY+KtRUSyx1lnnUXirQ7S3ZDnhRdeaJqC0sjKpqQBA0Lfgs5lEBHZW1YGQ0EB9O2rkUkiIqlkZTCAhqyKZJtM3a2yuWmM/czaYCgrUzCIZIvCwkLWrFnT6sPB3VmzZg2FhYUH9D5Z2fkM4YihshI2boQOHeKuRkQyqaSkhIqKCg70Rl8tQWFhISUlJQf0HlkdDBCOGoYPj7cWEcms/Px8Buo6+/WWtU1Juvy2iEhqCgYFg4hIkqwNho4doXt3ncsgIlJb1gYDaMiqiEgqCgYFg4hIkqwPhmXLILqpkoiIkOXBUFYGVVWwZEnclYiINB8ZCwYzu8/MVpvZnDTrv2xmb5vZO2b2spkdkala0tHIJBGRvWXyiOF+4NQ61i8GTnT3TwE/BCZnsJaUFAwiInvL2JnP7j7dzAbUsf7lhKevAgd2Dvd+6NEDiooUDCIiiZpLH8OlQNr72pnZRDObZWazGvNaJ2YwaJDOZRARSRR7MJjZWEIw3JBuG3ef7O4j3X1kcXFxo36+hqyKiCSLNRjM7HDg18B4d18TRw2lpbBoURidJCIiMQaDmfUD/gJc5O4L4qqjtBS2b4cVK+KqQESkeclY57OZTQHGAN3NrAK4CcgHcPdfAv8FdAP+18wAdrn7yEzVk07iyKQDvIS5iEirkMlRSeX7WH8ZcFmmPr++ysrC4wcfwIknxluLiEhzEHvnc9z69YO8PHVAi4hUy/pgyMuD/v0VDCIi1bI+GCD0M+hcBhGRQMGAzmUQEUmkYCAEw7p1sHZt3JWIiMRPwYAupicikkjBgIJBRCSRgoFwIT1QMIiIgIIBCJfe7tVLwSAiAgqGPTQySUQkUDBEdC6DiEigYIiUloYrrG7dGnclIiLxUjBEqkcmLVoUbx0iInFTMEQ0ZFVEJFAwRBQMIiKBgiHSrRt07KhgEBFRMETMNGRVRAQUDEnKyhQMIiIKhgSlpbB4MezaFXclIiLxUTAkKC0NobBsWdyViIjER8GQQCOTREQyGAxmdp+ZrTazOWnWm5ndZWYLzextMzsyU7XUl4JBRCSzRwz3A6fWsf404OBomgjck8Fa6qVPH2jTRsEgItktY8Hg7tOBum6WOR74nQevAp3NrFem6qmP3FwYOFDBICLZLc4+hj5AYjdvRbRsL2Y20cxmmdmsysrKjBalcxlEJNu1iM5nd5/s7iPdfWRxcXFGP6s6GNwz+jEiIs1WnMGwHOib8LwkWharsjLYtAlWr467EhGReMQZDNOAr0Sjkz4DrHf3jzL2aR89C098CrbX1e2hkUkiIpkcrjoFeAU4xMwqzOxSM7vCzK6INnkSWAQsBO4F/jNTtQBQ0A3Wz4Flj9S5mYJBRLJdXqbe2N3L97Hega9n6vP30mUEdBgMS6dA2dfSbjZwYLignoJBRLJVi+h8bhRm0L8cVr0AW1ak3aygAEpKFAwikr2yJxgABpQDDh8+VOdmGrIqItksu4Kh4yGhSWnJg3VupmAQkWyWXcEAMOACWDsTNi5Mu0lpaRiuunFjE9YlItJMZF8w9Ds/PC6dmnYTjUwSkWyWfcFQ1BeKjw+jk9Kc3lxWFh4VDCKSjbIvGCB0Qq+fB+veSblaRwwiks2yMxj6fgksF5am7oTu1Am6dVMwiEh2ys5gKCyGnp8P/QxpmpM0MklEslV2BgOE5qTNS+HjV1KuVjCISLbK3mAoOQtyC0MndAqlpfDhh7BjRxPXJSISs+wNhvwO0PuMcBZ01a69VpeWQlUVLF0aQ20iIjHK3mCA0Jy0bTWs+udeq6pHJi1Mfx6ciEirlN3B0Pt0yO+YsjlJQ1ZFJFtldzDkFkLfL8Kyv8DubUmrevWCtm0VDCKSfeoVDGZWZGY50fxgMxtnZvmZLa2J9C+HnRtgxVNJi800MklEslN9jximA4Vm1gd4BrgIuD9TRTWpHp+FwoNSXnG1rAzefjt0QouIZIv6BoO5+xbgi8D/uvu5wLDMldWEcvKg77mw4m/hyCHB+eeHUUl/+UtMtYmIxKDewWBmo4EvA09Ey3IzU1IMBlwQ+hgq/pq0+NxzYfBg+NGP0p4gLSLS6tQ3GL4FTAIedfe5ZjYIeD5zZTWx7qOhqD8sSR6dlJsLN94Ib70Fjz8eU20iIk2sXsHg7v9y93Hu/pOoE/pjd786w7U1HTPoPwFWPgPbKpNWXXABDByoowYRyR71HZX0oJl1NLMiYA4wz8yuq8frTjWz+Wa20My+m2J9PzN73szeMLO3zez0hu9CI+lfDr4blv05aXF+PkyaBDNnwjPPxFSbiEgTqm9T0lB33wCcBTwFDCSMTErLzHKBu4HTgKFAuZkNrbXZ94GH3H0EMAH43wbU3rg6Hw6dhu7VnATwla9ASQn88Ic6ahCR1q++wZAfnbdwFjDN3XcC+/qJHAUsdPdF7r4DmAqMr7WNAx2j+U7AinrW0/jMwlFD5YuweVnSqoICuOEGeOkl+Ne/YqpPRKSJ1DcYfgUsAYqA6WbWH9hQ5yugD5D4C1sRLUt0M3ChmVUATwLfSPVGZjbRzGaZ2azKyspUmzSO/hPCY4r7QV96KfTsGY4aRERas/p2Pt/l7n3c/XQPlgJjG+Hzy4H73b0EOB34ffUZ1rU+f7K7j3T3kcXFxY3wsWl0KIOuR6W8dlLbtnDttfDPf8LLL2euBBGRuNW387mTmd1R/Ve7mf034eihLsuBvgnPS6JliS4FHgJw91eAQqB7vSrPlAHl8MkbsGH+XquuuAK6dw8jlEREWqv6NiXdB2wEzoumDcBv9/GamcDBZjbQzNoQOpen1drmQ+AkADMbQgiGDLYV1UO/8wFL2QldVATXXANPPQWzZjV9aSIiTaG+wVDq7jdFHcmL3P3/AIPqeoG77wKuAp4G3iWMPpprZreY2bhos+8AXzOzt4ApwMXuMY/7adcbeowJzUkpSvn616FzZ7j11qYvTUSkKdQ3GLaa2XHVT8zsWGDrvl7k7k+6+2B3L3X3W6Nl/+Xu06L5ee5+rLsf4e7D3b15nCnQvxw2LoBPZu+1qmNH+OY34bHHwgX2RERam/oGwxXA3Wa2xMyWAL8ALs9YVXHrew7k5KdsTgK4+mro0EFHDSLSOtV3VNJb7n4EcDhweHRC2mczWlmcCrpCz1Pgwz+B733N7a5dQ5PSww/De+/FUJ+ISAY16A5u7r4hOgMa4JoM1NN8DLgAtlRA5b9Trr7mmjCE9cc/buK6REQy7EBu7WmNVkVzVDIOctulvIEPQHFxGL764IO6y5uItC4HEgyt+6pBeUWhr2HxA/BJ6l7ma6+FvDy47bYmrk1EJIPqDAYz22hmG1JMG4HeTVRjfEb8DPI7w7/PhZ0b91rdqxdcdhk88AB8+GEM9YmIZECdweDuHdy9Y4qpg7vnNVWRsWnbA46dCpsWwozLU57XcP314fGnP23i2kREMuRAmpKyQ48T4VO3hBPeFk7ea3W/fvDVr8Kvfw0ffRRDfSIijUzBUB/DJkGvU+D1b8LaN/ZaPWkS7NoFP/tZDLWJiDQyBUN9WA6M/j0UdId/nwc7k684PmgQfPnL8MtfQiavCi4i0hQUDPVVWBz6GzYvhtcu26u/YdIk2LYN7rgjpvpERBqJgqEhDjoOjrgVPnwY3k++C+mhh8J558EvfgFr18ZUn4hII1AwNNSQ66D36TD7Glj7etKq730PNm0KjyIiLZWCoaEsB0b/Dgp7wIvnwo51e1Z96lPwne+Evoaf/zzGGkVEDoCCYX8UdINj/wRblsGrlyT1N/zkJ3D22fDtb8Ojj8ZYo4jIflIw7K/i0TD8Nqh4FObftWdxbi784Q8walQYqfTaazHWKCKyHxQMB+LQa6DPOHjzOvh4xp7F7drBtGnQsyeceSYsWhRjjSIiDaRgOBBmMPp+aNsbXjoPttcMRzroIHjyyXDi2+mna6SSiLQcCoYD1aYLHPsQbF0Br16c1N9w6KHhFqCLF8MXvwjbt8dXpohIfSkYGkP3UTDidlj+OLz330mrTjgBfvtb+Ne/4NJLU16HT0SkWWn9V0htKoO/Aaunw5vfhS5HQs+aO59ecEE4avj+98PlM265JcY6RUT2IaNHDGZ2qpnNN7OFZvbdNNucZ2bzzGyumaW+XVpLYAZH/wY6HAzPnwLz/yfp8ODGG8MRww9/GI4gRESaq4wFg5nlAncDpwFDgXIzG1prm4OBScCx7j4M+Fam6mkSbTrB51+B3qfB61fDyxfCrs1AyI177oGTT4aJE+G552KuVUQkjUweMYwCFrr7InffAUwFxtfa5mvA3e7+CYC7r85gPU2jTWc44TE4/EfhHg5PfwY2vA9Afj48/DAMGQLnnANz5sRcq4hICpkMhj7AsoTnFdGyRIOBwWb2kpm9amanpnojM5toZrPMbFZlS7iuteXAYd+DsX8Po5WeHgkVfwWgUyd44gkoKgrDWFesiLlWEZFa4h6VlAccDIwByoF7zaxz7Y3cfbK7j3T3kcXFxU1c4gHo9Xk49fXQ7zD9LHjre1C1m759QzisXRtOgNu0Ke5CRURqZDIYlgN9E56XRMsSVQDT3H2nuy8GFhCCovVoPwBO/jeUXgZzfwwvnAbbPmbECHjoIXjzTZgwAXbujLtQEZEgk8EwEzjYzAaaWRtgAjCt1jaPEY4WMLPuhKal1ncBidxCOPpeGHVvGNL690/DmpmcfjrcfXc4evjsZ2HlyrgLFRHJYDC4+y7gKuBp4F3gIXefa2a3mNm4aLOngTVmNg94HrjO3ddkqqbYlV0Wjh4Anj0OFt7LFVfAlCkwezYceSS88kq8JYqImLewU3FHjhzps2bNiruMA7PtY3j5y7DyGRh0CYz8BW/Pa8vZZ8OyZXDXXXD55WGIq4hIYzCz1919ZH22jbvzOTsVdocxT8Kw78Oi++DZYzm81yvMmgWf+xxceWU4GW7btrgLFZFspGCIS04uHPFDOGEabF0Ozx5DlzdP528PzOQHPwhnRx9/PHz4YdyFiki2UTDEreRMGLcIhv8E1s4g59lR3HLSOJ7/y5ssWACf/jT8859xFyki2UTB0BzkFcHQ62Hc4nDG9OoXGbN1BBVTzmH00DmcfDLcfruuzCoiTUPB0JzkdwhnTI9fDIfdRIfNz/HXyw9n+o8n8Os73mPCBJ0MJyKZp2Bojtp0hsNvhnGLsWGTOGbg35j3s2Gc2e0izj/9fRYujLtAEWnNFAzNWUFXOOJWbNxicoZ+h/LjHuGvXxvCq3dewnOPfRB3dSLSSikYWoLCYhjxU3LPXsTmkm9w7qgH+dyWMt658yTWvP4H2LUl7gpFpBVRMLQkbXvSaez/g3GL+Ncnt1DEErrNv4jtU3ux+5WJUPmKeqhF5IDpzOcWbMniKu798YscnPtbzvvMw7RrswU6HgIDL4aBX4F2veMuUUSaCZ35nCUGDMzh1ntPpPjM+/nMT1ZyyeTf8N7iYnhrEvy1Lzx/Onz4MOzeHnepItKCKBhagS98AWa80YH+Yy9h+HUvMvwHC3h143fxdW/Dv8+DR3vDrG9A5ctQtTvuckWkmVMwtBKFhXDTTTBvHpQMOZjRl9/K4T9Yyltd/w49T4aF98Kzx8KjPeHV/4Blf4GdOilCRPamYGhlBg2Cv/0Npk2DTZtzGX7aKVz4y6msPGYlHDMFen4elj0GL54Dj3QLzU3v3wNbKuIuXUSaCXU+t2JbtsBtt8FPfgIFBfDd78JVV0HH9juh8t9Q8TgsnwabonMiuoyAPuPC9Zu6HKnrfou0Ig3pfFYwZIGFC+Gaa+Dxx6FzZ/jmN+Hqq6FrV8Lw1g3vhYBY/njoh8ChbR/ocwb0GAvFx2uEk0gLp2CQlGbPhh/9CB59FNq3h69/PQTGQQclbLStElY8GYLio2dgV9QP0b4UDjohTMXHQ/tBOqIQaUEUDFKnOXPg1lvhT38KndaXXw7XXQe9ax8UVO2CT94I96mufBFWvwg71oZ1bXuHgKgOi05DwdRlJdJcKRikXubPD30Qv/895OaGu8bdcAP075/mBV4F69+FyukhLFZPh60rwro2XUJQdB8NnQ+DTodBUT+FhUgzoWCQBlm8OHRQ33df6HL4yldg0iQoK9vHC91h8+JwJFEdFJsSLv2aVwQdh0LnYdBpWAiLTsOgXYmaoUSamIJB9ktFBfzsZzB5MuzYARMmhE7qUaMa8Du+4xNYPw/Wz4V1c2H9nDC/bVXNNvkdEwIjCotOQ0PzlAJDJCOaTTCY2anAz4Fc4Nfuflua7c4B/gwc5e51/uorGDJv5Uq44w64555wY6BPfQomToQLLwyjmvbL9jUhINbPhXVzaua3f1yzTX6nEBCdhoawqA6Ptn0UGCIHqFkEg5nlAguAk4EKYCZQ7u7zam3XAXgCaANcpWBoPjZuhKlTwxHErFnQti2cd14IidGjG+m3etvqmiOMxMftlTXb5HWoCYvq4Gg/CNr1g7y2jVCESOvXXIJhNHCzu58SPZ8E4O7/t9Z2dwLPAtcB1yoYmqfZs+Hee+GPfwyBMWxYCIiLLoIuXTLwgdsqQ0BsmJccGIlNUgCFB0HRACjqH00Dkh/zO2SgOJGWp7kEw5eAU939suj5RcDR7n5VwjZHAt9z93PM7AXSBIOZTQQmAvTr1+/TS5cuzUjNsm+bNoVhrpMnw4wZYbjrueeGkDj22CZo8dm+JoyM2rwENi+NpoT5qlpXkm3TJYREu75Q2KNmatsj+Xl+JzVXSavWkGDIy3Qx6ZhZDnAHcPG+tnX3ycBkCEcMma1M6tK+fRjWeuml8Oab4SjiD38IQ16HDAnLJ0yAPn0yVEBBNzjoOOC4vdd5VWiaShUYm5fAmtdCE5VX7f3anIJw9FHYI/XUtgcUROsLumoYrrRqsTUlmVkn4AOg+hKfPYG1wLi6mpPUlNT8bN4MDz0Ev/oVvPZa+MP7xBOhvBzOOQe6dYu7wgRVu2HHmtAktW0VbI0et62sWbZnWg2e4jLllhdut7pXgBwE+Z1D81V+x9A3kt8x+Xlum6bfZxGaT1NSHqHz+SRgOaHz+QJ3n5tm+xdQH0OLt2ABTJkSpvnzIS8PTj01hMS4ceGIo8XwKti+FravrhUitcKjer52M1YqOQW1gqPW/J5laZbvCZuOkFuo5i+pt2YRDFEhpwN3Eoar3ufut5rZLcAsd59Wa9sXUDC0Gu7wxhshIKZODedItGsHZ54JF1wAp5wSrvjaarjDro2wY3143LkBdkaPtZ/XXlZ7ftfm+n2m5dWExJ4g6ZhiWQfIaQM5eeE1OXlguXvP136eWxCCrPoxp02tZW3UpJYJSb/JnrzMbL//zdpwpy8AAAxvSURBVJtNMGSCgqHlqaqCl16CBx+Ehx+GNWvC+RDnnBOOJMaMCZfkkEjVbti9OSFIqsMjMWgSQiYpaGotq2/I7K+c/JrQSAwfy4vW5dUKnYRHywU8NNclTVUplkXL8SiYCsOUUxhCas989VRQ89xygarofatq3j9xGVXR3Q0T1vuums+uql3Lrr3rq9oBVTsTpui570y9bk8zZQN+g4feAMNTng62TwoGabZ27oTnngtHEo8+GkY5FRfDGWfA+PFw8snhyEIaSdWucIXcqp01P2ZVu1LM74p+/Krnox+v3dtDE1n1Y6ple9ZFn5H0nrvqXmYWHaHUnnJSL4eohm01U9W2UMOe+YQp7Y+uJXxODpBT85kY5OTWhFftKSfd8jYhDC0/9CVZfhSO0fLa6yw3oSmw1mNSE2HCuuJjoOdJ+/WfgoJBWoQtW+DJJ0NAPPEErF8fTqI7+eQQEmeeGUJDZL+4JwRQYghYVvbNKBikxdmxA6ZPh7/+NUzLloX/d489NoTE+PFw8MFxVynScikYpEVzD+dIPPZYCIm33grLhwypCYmjjlK/hEhDKBikVVmyBKZNC0ExfTrs3h06r8eOhc99Dk46CQYPzsrWAZF6UzBIq7V2Lfz97/CPf4RO7A8/DMv79KkJiZNOSnE3OpEsp2CQrOAOH3wQQuIf/4B//jMMhYXQ7FQdEmPGHMDlwkVaCQWDZKWqqtAfUR0U06eHkU85OfDpT8Pxx4fpuOOge/e4qxVpWgoGEcJIp1dfDSHxwgvhOk7bo6tWDBlSExTHH1/Hfa5FWgkFg0gK27eHGw69+GKYXnopnDsB0LdvclAMGRKONERaCwWDSD3s3g1z5tQExYsvwkcfhXVdu4a71I0aBUcfHYbHdu0ab70iB0LBILIf3GHRopqQeO01mDev5vplZWU1QTFqFAwfHm5UJNISKBhEGsnGjaH5acaMmqmiIqzLy4MjjkgOi8GDdeKdNE8KBpEMWrEiOShmzoQNG8K6du1CWIwYUTMddlgru8S4tEgKBpEmVFUVbko0Y0a4B8Xs2eGSHhs3hvV5eTBsWHJYHHEEdOwYb92SXRQMIjGrqgr9FW+8UTPNng2rV9dsU1YW+imGDQvT0KHhQoFtdPdPyYCGBENeposRyUY5OeGHv6wMzj03LHMPo54Sw+KNN+CRR2o6uHNzQzhUB8XQoWF+8GA1R0nTUTCINBGzcA2n3r3hC1+oWb51a2iKmjcP5s4Nj++8E+5TUVUVtsnNhdLSmsAYMiQ8HnKIbmwkjU/BIBKztm1Dk9Lw4cnLt22DBQuSA2Pu3HCl2d3RXSHNYMCAmqCoDo0hQ6BTpybfFWklFAwizVRhIRx+eJgS7dgB778P774bwmLevDD/j3/UXPIDwpFJdVAMHhyaqA4+GPr1Cx3iIunoPw+RFqZNm5oO60S7d8PixclhMW8e3HcfbN5cs11+PgwcWBMUZWXJoaHzMCSjwWBmpwI/B3KBX7v7bbXWXwNcBuwCKoFL3H1pJmsSaa1yc2s6vMeNq1nuDitXhqOM99+HhQtrHp9/PlyBtlp+PgwaFN6jtDTMDxxY81hU1PT7JU0vY8FgZrnA3cDJQAUw08ymufu8hM3eAEa6+xYzuxL4KXB+pmoSyUZm0KtXmE44IXld9Uip6rBIDI7p02vOxajWo0cIieqpOjQGDQpNVzraaB0yecQwCljo7osAzGwqMB7YEwzu/nzC9q8CF2awHhGpJXGkVKrQWLMmnI+xeHF4rJ5eegmmTKkZNQWh36JPn9Ac1bdvmGrPd+miW7C2BJkMhj7AsoTnFcDRdWx/KfBUqhVmNhGYCNCvX7/Gqk9E6mAWbmjUvXu4DlRtO3eGW6tWh8XSpbBsWVj2yivw8MNhm0Tt2u0dGLWfq7kqfs2i89nMLgRGAiemWu/uk4HJEM58bsLSRCSN/PzQD1Famnp9VRWsWlUTFomPy5aFczVWrtz7dV26pA6P6ql3b13VNtMyGQzLgb4Jz0uiZUnM7HPA94AT3X177fUi0jLl5NT0baQ64oAw9Hb58pqwqJ6qA+Tll2Ht2r1f17VrTRNYuqlnzxBe0nCZDIaZwMFmNpAQCBOACxI3MLMRwK+AU9199d5vISKtWZs2oQN74MD022zeHC51Xh0aH30UrnC7fHl4nDcvLKs+6a+aGRQXh4AoLoaDDgqPiVPiss6ddde+ahkLBnffZWZXAU8Thqve5+5zzewWYJa7TwN+BrQHHrbQI/Whu49L+6YiknWKisKlPw45JP02u3fDxx+HoEgMjeXLQ3NWZWW4+m1lZc0l0mvLza0JiR49aqaePfd+7N69dY/A0tVVRSSrbN8eAiJxWr06eX716tD/sWpVuJZVbTk5IRyqw6JHj/C8W7f0U9zXtNLVVUVE0igogJKSMO2LeziXY9WqMFWHRfVj9fyCBWFo76ZN6d+rsDAERHWAdO0aOtqrH2vPVz/v0KHpm7gUDCIiaZiFGyp17BguGbIv27eHzvI1a+qePv4Y5syBTz4J044d6d8zJyf0f3TpAldeCd/5TuPtXzoKBhGRRlJQUDMSq77cw2VJqkPik09CuKR63rNn5mpPpGAQEYmRWehgLyqqX/NWU9DgLBERSaJgEBGRJAoGERFJomAQEZEkCgYREUmiYBARkSQKBhERSaJgEBGRJC3uInpmVgks3c+Xdwc+bsRyWpps3v9s3nfI7v3Xvgf93b24Pi9qccFwIMxsVn2vLtgaZfP+Z/O+Q3bvv/a94fuupiQREUmiYBARkSTZFgyT4y4gZtm8/9m875Dd+699b6Cs6mMQEZF9y7YjBhER2QcFg4iIJMmaYDCzU81svpktNLPvxl1PUzKzJWb2jpm9aWaz4q4n08zsPjNbbWZzEpZ1NbNnzez96LFLnDVmSpp9v9nMlkff/5tmdnqcNWaKmfU1s+fNbJ6ZzTWzb0bLs+W7T7f/Df7+s6KPwcxygQXAyUAFMBMod/d5sRbWRMxsCTDS3bPiJB8zOwHYBPzO3Q+Llv0UWOvut0V/GHRx9xvirDMT0uz7zcAmd789ztoyzcx6Ab3cfbaZdQBeB84CLiY7vvt0+38eDfz+s+WIYRSw0N0XufsOYCowPuaaJEPcfTqwttbi8cAD0fwDhP9hWp00+54V3P0jd58dzW8E3gX6kD3ffbr9b7BsCYY+wLKE5xXs5z9YC+XAM2b2uplNjLuYmPRw94+i+ZVAjziLicFVZvZ21NTUKptSEpnZAGAE8BpZ+N3X2n9o4PefLcGQ7Y5z9yOB04CvR80NWctD+2nrb0OtcQ9QCgwHPgL+O95yMsvM2gOPAN9y9w2J67Lhu0+x/w3+/rMlGJYDfROel0TLsoK7L48eVwOPEprWss2qqA22ui12dcz1NBl3X+Xuu929CriXVvz9m1k+4Ufxj+7+l2hx1nz3qfZ/f77/bAmGmcDBZjbQzNoAE4BpMdfUJMysKOqIwsyKgM8Dc+p+Vas0DfhqNP9V4K8x1tKkqn8UI2fTSr9/MzPgN8C77n5Hwqqs+O7T7f/+fP9ZMSoJIBqidSeQC9zn7rfGXFKTMLNBhKMEgDzgwda+72Y2BRhDuOTwKuAm4DHgIaAf4bLt57l7q+ukTbPvYwjNCA4sAS5PaHNvNczsOOBF4B2gKlp8I6GdPRu++3T7X04Dv/+sCQYREamfbGlKEhGRelIwiIhIEgWDiIgkUTCIiEgSBYOIiCRRMIjUYma7E65E+WZjXo3XzAYkXvlUpDnKi7sAkWZoq7sPj7sIkbjoiEGknqL7Wvw0urfFDDMri5YPMLN/Rhcp+4eZ9YuW9zCzR83srWg6JnqrXDO7N7pm/jNm1ja2nRJJQcEgsre2tZqSzk9Yt97dPwX8gnAmPcD/AA+4++HAH4G7ouV3Af9y9yOAI4G50fKDgbvdfRiwDjgnw/sj0iA681mkFjPb5O7tUyxfAnzW3RdFFytb6e7dzOxjwg1SdkbLP3L37mZWCZS4+/aE9xgAPOvuB0fPbwDy3f1Hmd8zkfrREYNIw3ia+YbYnjC/G/X1STOjYBBpmPMTHl+J5l8mXLEX4MuEC5kB/AO4EsLtZc2sU1MVKXIg9JeKyN7amtmbCc//7u7VQ1a7mNnbhL/6y6Nl3wB+a2bXAZXAf0TLvwlMNrNLCUcGVxJulCLSrKmPQaSeoj6Gke7+cdy1iGSSmpJERCSJjhhERCSJjhhERCSJgkFERJIoGEREJImCQUREkigYREQkyf8HELhUP3XhkLYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of Best model on the Test Set"
      ],
      "metadata": {
        "id": "pweqWLFSNHHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the Test Set\n",
        "bleu_score, sari_score = evaluate_model(transformer, TEST_PAIRS, word_tk_mem)"
      ],
      "metadata": {
        "id": "iE_I1kUD7yKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Bleu score: {bleu_score['bleu']}\")\n",
        "print(f\"Sari score: {sari_score['sari']}\")"
      ],
      "metadata": {
        "id": "i-kanoJQzIJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cdf606-2700-4585-c1e3-45578f7b14c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu score: 0.34301430954549905\n",
            "Sari score: 19.100196607914054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We try our model on several test sentences in order to better visualize the predictions\n",
        "\n",
        "test_texts = [pair[0] for pair in TEST_PAIRS]\n",
        "\n",
        "for _ in range(15):\n",
        "    input_sentence = random.choice(test_texts)\n",
        "    print(convert_seq_to_text(input_sentence, IDX_TO_WORD))\n",
        "    translated = decode_sequence(transformer, input_sentence, IDX_TO_WORD, WORD_TO_IDX)\n",
        "    print(translated)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTkj66N7x6xC",
        "outputId": "eaaaf83b-04cc-4eb3-a1b3-e2c0f135aaaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "la sintassi più semplice è quella seguente . \n",
            "[start] la sintassi è la seguente . [end]\n",
            "\n",
            "\n",
            "è solo una mia opinione , ovviamente . \n",
            "[start] ovviamente è solo una mia opinione . [end]\n",
            "\n",
            "\n",
            "cosa può dirme al riguardo ? \n",
            "[start] cosa puoi dire al riguardo ? [end]\n",
            "\n",
            "\n",
            "nell attesa di un urgentissimo riscontro , distinti saluti . \n",
            "[start] in attesa di un riscontro porgiamo distinti saluti . [end]\n",
            "\n",
            "\n",
            "la ringrazio infinitamente per la cortese attenzione e porgo distinti saluti . \n",
            "[start] la ringrazio per l attenzione e le porgo distinti saluti . [end]\n",
            "\n",
            "\n",
            "ma oramai la frittata era fatta . \n",
            "[start] ma la frittata è fatta . [end]\n",
            "\n",
            "\n",
            "la differenziazione delle tematiche affrontate è più che buona mentre è accettabile la capacità dimostrata nell attivare nuovi filoni culturali . \n",
            "[start] la differenziazione delle tematiche affrontate è buona così come buona e così semplice è sufficiente ai fini della chiusura . [end]\n",
            "\n",
            "\n",
            "non si può far finta di niente . \n",
            "[start] non possiamo far finta di niente . [end]\n",
            "\n",
            "\n",
            "il comitato si riunisce almeno due volte all anno . \n",
            "[start] il comitato viene prese a due volte ai fatti . [end]\n",
            "\n",
            "\n",
            "e probabilmente questo è stato un bene . \n",
            "[start] ed è stato un bene . [end]\n",
            "\n",
            "\n",
            "a cosa può essere dovuto ? ? \n",
            "[start] a che cosa può essere dovuto ? [end]\n",
            "\n",
            "\n",
            "ahimè , quelli sono sotto gli occhi di tutti . \n",
            "[start] è sotto gli occhi di tutti . [end]\n",
            "\n",
            "\n",
            "non fatemi del male . \n",
            "[start] non vogliamo fare del male a nessuno . [end]\n",
            "\n",
            "\n",
            "il comma 14 è soppresso . \n",
            "[start] il comma 4 è soppresso . [end]\n",
            "\n",
            "\n",
            "la materia è , come poche , complessa e delicata . \n",
            "[start] la materia è difficile , difficile . [end]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Transformer_supervised.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}